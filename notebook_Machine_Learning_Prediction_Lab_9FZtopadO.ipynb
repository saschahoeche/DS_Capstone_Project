{"cells": [{"metadata": {}, "id": "41092b48-3d26-4826-9516-ccaea45f5040", "cell_type": "markdown", "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n    </a>\n</p>\n"}, {"metadata": {}, "id": "a7b195fb-7957-4e70-9739-a26fc8eb95bb", "cell_type": "markdown", "source": "# **Space X  Falcon 9 First Stage Landing Prediction**\n"}, {"metadata": {}, "id": "3b088492-0aa6-4e07-a816-0b74dbc58203", "cell_type": "markdown", "source": "## Assignment:  Machine Learning Prediction\n"}, {"metadata": {}, "id": "19c6c99b-e968-4d6e-a07a-38307d36ed2b", "cell_type": "markdown", "source": "Estimated time needed: **60** minutes\n"}, {"metadata": {}, "id": "a4bec0cd-b2fe-48ff-8a60-44d57af5473c", "cell_type": "markdown", "source": "Space X advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars; other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage. Therefore if we can determine if the first stage will land, we can determine the cost of a launch. This information can be used if an alternate company wants to bid against space X for a rocket launch.   In this lab, you will create a machine learning pipeline  to predict if the first stage will land given the data from the preceding labs.\n"}, {"metadata": {}, "id": "9b9e79e6-8497-49ce-b2e1-e914bf87726c", "cell_type": "markdown", "source": "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/landing_1.gif)\n"}, {"metadata": {}, "id": "0fc39343-e511-4f02-aaaa-930eb60428d7", "cell_type": "markdown", "source": "Several examples of an unsuccessful landing are shown here:\n"}, {"metadata": {}, "id": "d8f06dd0-f33f-4d53-9a20-580a42011408", "cell_type": "markdown", "source": "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/crash.gif)\n"}, {"metadata": {}, "id": "ef614108-fd8d-4344-948a-39d131d671df", "cell_type": "markdown", "source": "Most unsuccessful landings are planed. Space X; performs a controlled landing in the oceans.\n"}, {"metadata": {}, "id": "21c1b9fb-9eed-461b-8c77-5c0950a00e6f", "cell_type": "markdown", "source": "## Objectives\n"}, {"metadata": {}, "id": "25fe0855-ff49-4adb-8954-6c46fab06877", "cell_type": "markdown", "source": "Perform exploratory  Data Analysis and determine Training Labels\n\n*   create a column for the class\n*   Standardize the data\n*   Split into training data and test data\n\n\\-Find best Hyperparameter for SVM, Classification Trees and Logistic Regression\n\n*   Find the method performs best using test data\n"}, {"metadata": {}, "id": "28d653b1-3b9a-429e-80e0-02bd16de722e", "cell_type": "markdown", "source": "## Import Libraries and Define Auxiliary Functions\n"}, {"metadata": {}, "id": "4818736e-9044-4cbe-9367-8b21b0246077", "cell_type": "code", "source": "!pip install numpy pandas seaborn js", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: numpy in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (1.23.1)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (1.4.3)\nRequirement already satisfied: seaborn in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (0.11.2)\nRequirement already satisfied: js in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (1.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pandas) (2022.1)\nRequirement already satisfied: scipy>=1.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from seaborn) (1.8.1)\nRequirement already satisfied: matplotlib>=2.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from seaborn) (3.5.2)\nRequirement already satisfied: fanstatic in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from js) (1.3)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from js) (65.6.3)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (4.25.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (21.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (1.4.2)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (9.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\nRequirement already satisfied: WebOb>=1.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from fanstatic->js) (1.8.7)\n", "name": "stdout"}]}, {"metadata": {}, "id": "e3bd986c-7b04-48d7-bdbe-1e3067039e5f", "cell_type": "markdown", "source": "We will import the following libraries for the lab\n"}, {"metadata": {}, "id": "8513bd32-b465-4ded-8bd1-75315990d233", "cell_type": "code", "source": "# Pandas is a software library written for the Python programming language for data manipulation and analysis.\nimport pandas as pd\n# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\nimport numpy as np\n# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.\nimport matplotlib.pyplot as plt\n#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics\nimport seaborn as sns\n# Preprocessing allows us to standarsize our data\nfrom sklearn import preprocessing\n# Allows us to split our data into training and testing data\nfrom sklearn.model_selection import train_test_split\n# Allows us to test parameters of classification algorithms and find the best one\nfrom sklearn.model_selection import GridSearchCV\n# Logistic Regression classification algorithm\nfrom sklearn.linear_model import LogisticRegression\n# Support Vector Machine classification algorithm\nfrom sklearn.svm import SVC\n# Decision Tree classification algorithm\nfrom sklearn.tree import DecisionTreeClassifier\n# K Nearest Neighbors classification algorithm\nfrom sklearn.neighbors import KNeighborsClassifier", "execution_count": 2, "outputs": []}, {"metadata": {}, "id": "2a2bf13b-19b1-43d6-a2cd-d2f20bd69fb5", "cell_type": "markdown", "source": "This function is to plot the confusion matrix.\n"}, {"metadata": {}, "id": "1f30279e-9d5e-4df5-a814-8053d099c511", "cell_type": "code", "source": "def plot_confusion_matrix(y,y_predict):\n    \"this function plots the confusion matrix\"\n    from sklearn.metrics import confusion_matrix\n\n    cm = confusion_matrix(y, y_predict)\n    ax= plt.subplot()\n    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n    ax.set_xlabel('Predicted labels')\n    ax.set_ylabel('True labels')\n    ax.set_title('Confusion Matrix'); \n    ax.xaxis.set_ticklabels(['did not land', 'land']); ax.yaxis.set_ticklabels(['did not land', 'landed']) \n    plt.show() ", "execution_count": 3, "outputs": []}, {"metadata": {}, "id": "c0abf51b-e8f8-4fa5-8275-1205554ba883", "cell_type": "markdown", "source": "## Load the dataframe\n"}, {"metadata": {}, "id": "e6b453e1-b094-4508-a4e1-5159ee52d46e", "cell_type": "markdown", "source": "Load the data\n"}, {"metadata": {}, "id": "303c7783-faac-4ca0-98a5-df6c89c65df4", "cell_type": "code", "source": "#from js import fetch\n#import io\n\n#URL1 = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv\"\n#resp1 = await js.fetch(URL1)\n#text1 = io.BytesIO((await resp1.arrayBuffer()).to_py())\n#data = pd.read_csv(text1)\n\n\nimport csv\nimport requests\nimport io\n\nurl = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv\"\nr = requests.get(url)\nr.encoding = 'utf-8'  # useful if encoding is not sent (or not sent properly) by the server\ncsvio = io.StringIO(r.text, newline=\"\")\ndata_csv = []\nfor row in csv.DictReader(csvio):\n    data_csv.append(row)\n\ndata = pd.read_csv(data_csv)", "execution_count": 13, "outputs": [{"output_type": "error", "ename": "ValueError", "evalue": "Invalid file path or buffer object type: <class 'list'>", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)", "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m csv\u001b[38;5;241m.\u001b[39mDictReader(csvio):\n\u001b[1;32m     20\u001b[0m     data_csv\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[0;32m---> 22\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_csv\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n", "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1233\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1232\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file path or buffer object type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n", "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'list'>"]}]}, {"metadata": {}, "id": "2bbe74d1-22a0-4164-a154-7b61fd30db7f", "cell_type": "code", "source": "data.head()", "execution_count": 10, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'data' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n", "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}]}, {"metadata": {}, "id": "0ca7bbd2-ed4e-4eef-8f27-be9309caed78", "cell_type": "code", "source": "URL2 = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_3.csv'\nresp2 = await fetch(URL2)\ntext2 = io.BytesIO((await resp2.arrayBuffer()).to_py())\nX = pd.read_csv(text2)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "02af7a31-bf3d-431a-ae95-fd146cd09329", "cell_type": "code", "source": "X.head(100)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "5fc5aab8-54d4-49d9-aff6-0dd579baa44f", "cell_type": "markdown", "source": "## TASK  1\n"}, {"metadata": {}, "id": "013d35ed-ebae-4e84-8c60-935e3a699346", "cell_type": "markdown", "source": "Create a NumPy array from the column <code>Class</code> in <code>data</code>, by applying the method <code>to_numpy()</code>  then\nassign it  to the variable <code>Y</code>,make sure the output is a  Pandas series (only one bracket df\\['name of  column']).\n"}, {"metadata": {}, "id": "bc72dffc-1032-4a3a-b84f-d2968b3faffc", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "4d79f1ca-2636-4221-895a-4afc091c73b0", "cell_type": "markdown", "source": "## TASK  2\n"}, {"metadata": {}, "id": "324ed6d1-626f-4c23-bf84-efd98f797280", "cell_type": "markdown", "source": "Standardize the data in <code>X</code> then reassign it to the variable  <code>X</code> using the transform provided below.\n"}, {"metadata": {}, "id": "9067e374-f502-44c6-a628-29186009fd45", "cell_type": "code", "source": "# students get this \ntransform = preprocessing.StandardScaler()", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "a6f007c0-65fe-408a-9af6-febef40b1e1b", "cell_type": "markdown", "source": "We split the data into training and testing data using the  function  <code>train_test_split</code>.   The training data is divided into validation data, a second set used for training  data; then the models are trained and hyperparameters are selected using the function <code>GridSearchCV</code>.\n"}, {"metadata": {}, "id": "c4a2cfde-e37a-475f-95ad-95246535ff18", "cell_type": "markdown", "source": "## TASK  3\n"}, {"metadata": {}, "id": "3b2ff7f9-f969-4ba2-a2bd-17f0b7d6464e", "cell_type": "markdown", "source": "Use the function train_test_split to split the data X and Y into training and test data. Set the parameter test_size to  0.2 and random_state to 2. The training data and test data should be assigned to the following labels.\n"}, {"metadata": {}, "id": "5da81a62-3998-436c-b96e-9e7a1db0825f", "cell_type": "markdown", "source": "<code>X_train, X_test, Y_train, Y_test</code>\n"}, {"metadata": {}, "id": "bef9d582-2c05-4a6f-ac6a-125766d093c7", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "e81b772b-0a2e-4f30-a774-8bff2b8fe8b0", "cell_type": "markdown", "source": "we can see we only have 18 test samples.\n"}, {"metadata": {}, "id": "77d6496a-d933-420f-9352-1c95a832b84d", "cell_type": "code", "source": "Y_test.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "1e778d63-eec7-4bf8-a83e-3397997026fa", "cell_type": "markdown", "source": "## TASK  4\n"}, {"metadata": {}, "id": "06a7589e-a488-431b-b329-c78ea814f020", "cell_type": "markdown", "source": "Create a logistic regression object  then create a  GridSearchCV object  <code>logreg_cv</code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>.\n"}, {"metadata": {}, "id": "93fd1432-7426-4005-8dfe-04380700d42d", "cell_type": "code", "source": "parameters ={'C':[0.01,0.1,1],\n             'penalty':['l2'],\n             'solver':['lbfgs']}", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "de49af42-d4af-4f3b-bbbb-3b7cc6793c21", "cell_type": "code", "source": "parameters ={\"C\":[0.01,0.1,1],'penalty':['l2'], 'solver':['lbfgs']}# l1 lasso l2 ridge\nlr=LogisticRegression()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "a75d5bed-04e0-447a-a14a-eb0229e8da9e", "cell_type": "markdown", "source": "We output the <code>GridSearchCV</code> object for logistic regression. We display the best parameters using the data attribute <code>best_params\\_</code> and the accuracy on the validation data using the data attribute <code>best_score\\_</code>.\n"}, {"metadata": {}, "id": "8dfcfcaf-4c12-44f5-b7e4-3d00e56313dc", "cell_type": "code", "source": "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\nprint(\"accuracy :\",logreg_cv.best_score_)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "5df3f620-3e95-406d-b01d-667801f1d09d", "cell_type": "markdown", "source": "## TASK  5\n"}, {"metadata": {}, "id": "8890f2b5-9f2a-478b-8772-078b2e55483d", "cell_type": "markdown", "source": "Calculate the accuracy on the test data using the method <code>score</code>:\n"}, {"metadata": {}, "id": "ecd83d0e-92bc-4c73-b6e7-a355725cc4ac", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "ef7d820b-6494-448b-99da-ddee09fac04b", "cell_type": "markdown", "source": "Lets look at the confusion matrix:\n"}, {"metadata": {}, "id": "d12d8520-4f14-4cbf-af23-23893d3d8854", "cell_type": "code", "source": "yhat=logreg_cv.predict(X_test)\nplot_confusion_matrix(Y_test,yhat)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "6c4f7b4d-7cfb-4ff3-bf60-7b71da3a88c0", "cell_type": "markdown", "source": "Examining the confusion matrix, we see that logistic regression can distinguish between the different classes.  We see that the major problem is false positives.\n"}, {"metadata": {}, "id": "93e8f80b-f9e9-43cc-8703-446e4032ce1a", "cell_type": "markdown", "source": "## TASK  6\n"}, {"metadata": {}, "id": "c6f9fa64-44d6-4472-8d1b-e859ad3308a4", "cell_type": "markdown", "source": "Create a support vector machine object then  create a  <code>GridSearchCV</code> object  <code>svm_cv</code> with cv - 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>.\n"}, {"metadata": {}, "id": "642cfb6b-2c24-4d0d-96ad-e01809716b19", "cell_type": "code", "source": "parameters = {'kernel':('linear', 'rbf','poly','rbf', 'sigmoid'),\n              'C': np.logspace(-3, 3, 5),\n              'gamma':np.logspace(-3, 3, 5)}\nsvm = SVC()", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "4ac8b9eb-801e-4596-bce7-fa7a980dd5ba", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "a017bdfd-1c68-4eec-9b88-6900d8971ced", "cell_type": "code", "source": "print(\"tuned hpyerparameters :(best parameters) \",svm_cv.best_params_)\nprint(\"accuracy :\",svm_cv.best_score_)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "41b16eb3-b7ec-401d-a44a-1d2ab4638af0", "cell_type": "markdown", "source": "## TASK  7\n"}, {"metadata": {}, "id": "97ce1130-daf0-4059-abcf-bdfcc15b5f0b", "cell_type": "markdown", "source": "Calculate the accuracy on the test data using the method <code>score</code>:\n"}, {"metadata": {}, "id": "7aedad55-850c-4383-b8d1-c2dc61895fe8", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "7d52749c-ace1-4457-b304-f0e459a2d057", "cell_type": "markdown", "source": "We can plot the confusion matrix\n"}, {"metadata": {}, "id": "2f45fbab-8fcb-4973-9aef-d1980e5283c8", "cell_type": "code", "source": "yhat=svm_cv.predict(X_test)\nplot_confusion_matrix(Y_test,yhat)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "76e0b51a-3ccd-49d4-a214-6ef189aedc2f", "cell_type": "markdown", "source": "## TASK  8\n"}, {"metadata": {}, "id": "1a136130-54e9-40d3-b775-758f69b30bf1", "cell_type": "markdown", "source": "Create a decision tree classifier object then  create a  <code>GridSearchCV</code> object  <code>tree_cv</code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>.\n"}, {"metadata": {}, "id": "d85a7713-82bc-4857-9a18-56f2f425abcc", "cell_type": "code", "source": "parameters = {'criterion': ['gini', 'entropy'],\n     'splitter': ['best', 'random'],\n     'max_depth': [2*n for n in range(1,10)],\n     'max_features': ['auto', 'sqrt'],\n     'min_samples_leaf': [1, 2, 4],\n     'min_samples_split': [2, 5, 10]}\n\ntree = DecisionTreeClassifier()", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "966e2a3f-d15a-4940-99cf-e9b3bc1b7df4", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "4c26b867-0f93-4713-bd7c-9bdef8dea18f", "cell_type": "code", "source": "print(\"tuned hpyerparameters :(best parameters) \",tree_cv.best_params_)\nprint(\"accuracy :\",tree_cv.best_score_)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "1a845437-17f0-4bd4-8e9a-06f30ef827bf", "cell_type": "markdown", "source": "## TASK  9\n"}, {"metadata": {}, "id": "60d92686-3013-45bf-9983-9bd33aa530f2", "cell_type": "markdown", "source": "Calculate the accuracy of tree_cv on the test data using the method <code>score</code>:\n"}, {"metadata": {}, "id": "55003514-94f0-459a-a6eb-093f1c5f9f05", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "78fb6d64-6239-4783-8974-23606d5754c0", "cell_type": "markdown", "source": "We can plot the confusion matrix\n"}, {"metadata": {}, "id": "c15ce013-6b4c-4723-9b04-7e60f23f6448", "cell_type": "code", "source": "yhat = tree_cv.predict(X_test)\nplot_confusion_matrix(Y_test,yhat)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "612dbb58-fb2f-47ee-a7bb-d77a00e6dbd3", "cell_type": "markdown", "source": "## TASK  10\n"}, {"metadata": {}, "id": "a748cd07-5a39-4cda-809d-3cea906bd148", "cell_type": "markdown", "source": "Create a k nearest neighbors object then  create a  <code>GridSearchCV</code> object  <code>knn_cv</code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>.\n"}, {"metadata": {}, "id": "0cee22b2-bcf7-471e-96cf-e63302a47b52", "cell_type": "code", "source": "parameters = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n              'p': [1,2]}\n\nKNN = KNeighborsClassifier()", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "ffbaf94b-0b03-4094-84b6-f5233194434c", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "6309852d-7fb4-400f-b44a-1a3a04f03fba", "cell_type": "code", "source": "print(\"tuned hpyerparameters :(best parameters) \",knn_cv.best_params_)\nprint(\"accuracy :\",knn_cv.best_score_)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "98e9e899-25da-4c9b-99eb-b680c559ebda", "cell_type": "markdown", "source": "## TASK  11\n"}, {"metadata": {}, "id": "9a20e83b-5c1b-440d-bba3-57c44a8605a6", "cell_type": "markdown", "source": "Calculate the accuracy of knn_cv on the test data using the method <code>score</code>:\n"}, {"metadata": {}, "id": "89196934-71d7-408d-9ff2-e99a934fb7de", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "a6cafe12-0a65-4cdc-8e44-67892989248e", "cell_type": "markdown", "source": "We can plot the confusion matrix\n"}, {"metadata": {}, "id": "7b021ac7-870a-445b-9459-021c9e78f745", "cell_type": "code", "source": "yhat = knn_cv.predict(X_test)\nplot_confusion_matrix(Y_test,yhat)", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "3a98ab95-6763-4bcc-ae98-d76fc1c0812b", "cell_type": "markdown", "source": "## TASK  12\n"}, {"metadata": {}, "id": "965a2d1d-7ac3-458c-ba11-10f97d22e927", "cell_type": "markdown", "source": "Find the method performs best:\n"}, {"metadata": {}, "id": "7e2da33c-70ca-46ae-98a7-9ed8cdb4dabe", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "2388a641-817f-4e15-815a-f66278c656b0", "cell_type": "markdown", "source": "## Authors\n"}, {"metadata": {}, "id": "8845aea5-d412-4eac-9b51-3457f0be2c0f", "cell_type": "markdown", "source": "[Pratiksha Verma](https://www.linkedin.com/in/pratiksha-verma-6487561b1/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork865-2023-01-01)\n"}, {"metadata": {}, "id": "02bdba00-e939-4425-b819-417baeb84f8c", "cell_type": "markdown", "source": "## Change Log\n"}, {"metadata": {}, "id": "91fce393-48e3-493a-a228-9d58989c4766", "cell_type": "markdown", "source": "| Date (YYYY-MM-DD) | Version | Changed By      | Change Description      |\n| ----------------- | ------- | -------------   | ----------------------- |\n| 2022-11-09        | 1.0     | Pratiksha Verma | Converted initial version to Jupyterlite|\n"}, {"metadata": {}, "id": "73d1479f-e16f-449f-a5fe-ef1d4e367a1a", "cell_type": "markdown", "source": "### <h3 align=\"center\"> IBM Corporation 2022. All rights reserved. <h3/>\n"}], "metadata": {"language_info": {"name": "python", "version": "3.10.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}}, "nbformat": 4, "nbformat_minor": 4}